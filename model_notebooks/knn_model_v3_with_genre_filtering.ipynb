{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "# Nearest neighbors will be the v1 model for sound drip\n",
    "# will give logistic regressiona nd \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "# textblob will be used to perform sentiment analysis down the road\n",
    "# from textblob import TextBlob\n",
    "\n",
    "# # Data is large and will need to be unzipped\n",
    "# import zipfile\n",
    "\n",
    "# # unzipping file\n",
    "# with zipfile.ZipFile(\"./data_collection/final_data/DF_v1.pkl.zip\",\"r\") as zip_ref:\n",
    "#     zip_ref.extractall(\".\")\n",
    "\n",
    "# reading in pickled data\n",
    "# song_list = pd.read_pickle(\"./DF_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALERT - THIS COULD POTENTIALLY BE USED TO PERFORM SENTIMENT ANALYSIS ON LYRICS DATA IN v2. FOR v1, DISREGARD\n",
    "\n",
    "# # creating polarity and subjectivity lists to be populated\n",
    "\n",
    "# lyrics_polarity = []\n",
    "# lyrics_subjectivity = []\n",
    "\n",
    "# # using a for loop to populate polarity and subjectivity lists\n",
    "# for title in song_list_df[\"lyrics\"]:\n",
    "#     try:\n",
    "#         blob_test = TextBlob = TextBlob(title)\n",
    "#         blob_sentiment = blob_test.sentiment\n",
    "#         # appending results to lists above\n",
    "#         lyrics_polarity.append(blob_sentiment[0])\n",
    "#         lyrics_subjectivity.append(blob_sentiment[1])\n",
    "#     except:\n",
    "#         lyrics_polarity.append(0)\n",
    "#         lyrics_subjectivity.append(0)\n",
    "\n",
    "# # adding polarity and subjectivity to df\n",
    "# song_list['lyrics_polarity'] = lyrics_polarity\n",
    "# song_list['lyrics_subjectivity'] = lyrics_subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Latest PKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_list = pickle.load(\"./DF_genres_hashed.pkl\",\"rb\")\n",
    "\n",
    "X = pickle.load(open(\"./data/song_list_v4_hashed(1).pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"genres\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove two NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id='63594c9b2f99411a8cbd18df04851fc4',client_secret='096168b2bd1f4378ae410726955c9ed8')\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "def get_popularity(trackID):\n",
    "    return sp.track(trackID)['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_popularity('5gNNUKhBzakQrbu8UaLori')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[202786, 'popularity'] = 18\n",
    "\n",
    "X.loc[202786]['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_popularity('25DO8ImBd90EhKEKuntxqN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[189355, 'popularity'] = 0\n",
    "\n",
    "X.loc[189355]['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"genres_stripped\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking Final Updated DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop([\"availability\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = './data/song_list_v5_hashed.pkl'\n",
    "pickle.dump(X, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnecessary columns\n",
    "X = X.drop([\"songid\",\"artist\",\"track\", \"duration_ms\",\"genres\",\"genres_stripped\"], axis=1)\n",
    "\n",
    "# checking that they're dropped\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_scaling = X.columns[0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_genre_hashed = X.columns[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[columns_for_scaling]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[columns_genre_hashed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# scaling data\n",
    "data_scaled = scaler.fit_transform(X[columns_for_scaling])\n",
    "\n",
    "# confirming scaling took place\n",
    "data_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data_scaled,columns=X[columns_for_scaling].columns).hist(figsize=(8,8), normed=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_for_model = np.concatenate((data_scaled,genres_hashed_array),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574018"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization - Skipping for Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18556701, 0.85040161, 0.58375125, 0.0846    , 0.        ,\n",
       "       1.        , 0.696     , 0.69854981, 1.        , 0.03660807,\n",
       "       0.39780036, 0.8       , 0.396     ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_normalization = columns_for_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['popularity', 'acousticness', 'danceability', 'energy',\n",
       "       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
       "       'speechiness', 'tempo', 'time_signature', 'valence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_for_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "data_normalized = normalizer.fit_transform(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valence isn't scaled appropriately\n",
    "# will have to scale before normalizing\n",
    "# pd.DataFrame(da,columns=columns_for_normalization).hist(figsize=(8,8), normed=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Classifier w/ Data scaled and Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open(\"./data/song_list_v5_hashed.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating model class\n",
    "knn1 = NearestNeighbors(n_neighbors=10000,algorithm='kd_tree',n_jobs=-1)\n",
    "\n",
    "# fitting model\n",
    "model_1 = knn1.fit(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running model to test output\n",
    "knn_results1 = knn1.kneighbors([data_normalized[3]])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     3, 103114, 427498, ...,   4754, 238090, 225254])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_results1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>songid</th>\n",
       "      <td>41RpZW2lxAdnqDd2nMBzLQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acousticness</th>\n",
       "      <td>4.54e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist</th>\n",
       "      <td>Hudson Mohawke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability</th>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms</th>\n",
       "      <td>138960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentalness</th>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness</th>\n",
       "      <td>0.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness</th>\n",
       "      <td>-1.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechiness</th>\n",
       "      <td>0.0662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>177.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_signature</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track</th>\n",
       "      <td>No One Could Ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genres</th>\n",
       "      <td>['bass music', 'scottish electronic', 'scottis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genres_stripped</th>\n",
       "      <td>'bass music', 'scottish electronic', 'scottish...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  1\n",
       "songid                                       41RpZW2lxAdnqDd2nMBzLQ\n",
       "popularity                                                       15\n",
       "acousticness                                               4.54e-05\n",
       "artist                                               Hudson Mohawke\n",
       "danceability                                                  0.662\n",
       "duration_ms                                                  138960\n",
       "energy                                                        0.823\n",
       "instrumentalness                                              0.952\n",
       "key                                                               4\n",
       "liveness                                                      0.343\n",
       "loudness                                                     -1.711\n",
       "mode                                                              0\n",
       "speechiness                                                  0.0662\n",
       "tempo                                                       177.745\n",
       "time_signature                                                    4\n",
       "track                                             No One Could Ever\n",
       "valence                                                       0.621\n",
       "genres            ['bass music', 'scottish electronic', 'scottis...\n",
       "genres_stripped   'bass music', 'scottish electronic', 'scottish..."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.loc[1][0:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model3.joblib']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model_1, 'model3.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting song id column from df to an array\n",
    "\n",
    "song_id_array3 = np.array(df['songid'])\n",
    "\n",
    "filename5 = './data/song_id_array3.pkl'\n",
    "pickle.dump(song_id_array3, open(filename5, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for result in knn_results1[0]:\n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    display(pd.DataFrame(df.loc[result][0:1]),pd.DataFrame(df.loc[result][1:2]),pd.DataFrame(df.loc[result][17:18]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model w/ Scaling and no Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating model class\n",
    "# knn2 = NearestNeighbors(n_neighbors=100,leaf_size=10,algorithm='kd_tree',n_jobs=-1)\n",
    "\n",
    "# fitting model\n",
    "# model2 = knn2.fit(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running model to test output\n",
    "# knn_results2 = knn2.kneighbors([data_scaled[1]])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_results2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(df.loc[1][1:18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0 \n",
    "# for result in knn_results2[0]:\n",
    "#     counter += 1 \n",
    "#     print(counter)\n",
    "#     display(pd.DataFrame(df.loc[result][0:1]),pd.DataFrame(df.loc[result][17:18]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering KK For Shared Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop takes KNN results and filters by source track genres\n",
    "# old\n",
    "filtered_list = []\n",
    "source_song_index = knn_results1[0][0]\n",
    "source_genre_list = df.loc[source_song_index][\"genres_stripped\"].split(\",\")\n",
    "# print(\"source_genre_list created\")\n",
    "for source_genre in source_genre_list:\n",
    "    source_genre = source_genre.strip(' ')\n",
    "#     print(\"source_genre_created\")\n",
    "    for output_song_index in knn_results1[0][1:]:\n",
    "        output_genre_list = df.loc[output_song_index][\"genres_stripped\"].split(\",\")\n",
    "#         print(\"output_genre_list created\")\n",
    "        for output_genre in output_genre_list:\n",
    "            output_genre = output_genre.strip(' ')\n",
    "#             print(\"output_genre_created\")\n",
    "            if source_genre == output_genre:\n",
    "                print(output_song_index,source_genre,output_genre)\n",
    "                filtered_list.append(output_song_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop takes KNN results and filters by source track genres\n",
    "# new\n",
    "filtered_lists = []\n",
    "knn_result_ouputs = knn_results1[0][1:]\n",
    "for source_song_index in range(0,5):\n",
    "    filtered_list = []\n",
    "    source_genre_list = genre_array[1][source_song_index]\n",
    "    print(source_genre_list)\n",
    "#     print(\"source_genre_list created\")\n",
    "#     for source_genre in source_genre_list:\n",
    "#         source_genre = source_genre.strip(' ')\n",
    "#     #     print(\"source_genre_created\")\n",
    "#         for output_song_index in knn_results1[0][1:]:\n",
    "#             output_genre_list = df.loc[output_song_index][\"genres_stripped\"].split(\",\")\n",
    "#     #         print(\"output_genre_list created\")\n",
    "#             for output_genre in output_genre_list:\n",
    "#                 output_genre = output_genre.strip(' ')\n",
    "#     #             print(\"output_genre_created\")\n",
    "#                 if source_genre == output_genre:\n",
    "#                     print(output_song_index,source_genre,output_genre)\n",
    "#                     filtered_list.append(output_song_index)\n",
    "\n",
    "# knn_results1 = knn1.kneighbors([data_normalized[3]])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list.insert(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bass music'\n",
      " 'scottish electronic'\n",
      " 'scottish hip hop'\n",
      " 'uk experimental electronic'\n",
      " 'wonky'\n"
     ]
    }
   ],
   "source": [
    "filtered_lists = []\n",
    "knn_result_ouputs = knn_results1[0][1:]\n",
    "for source_song_index in range(0,5):\n",
    "    filtered_list = []\n",
    "    source_genre_list = genre_array[1][source_song_index]\n",
    "    print(source_genre_list)\n",
    "    # print(\"source_genre_list created\")\n",
    "#     for source_genre in source_genre_list:\n",
    "#         source_genre = source_genre.strip(' ')\n",
    "#     #     print(\"source_genre_created\")\n",
    "#         for output_song_index in knn_result_ouputs:\n",
    "#             output_genre_list = df.loc[output_song_index][\"genres_stripped\"].split(\",\")\n",
    "#     #         print(\"output_genre_list created\")\n",
    "#             for output_genre in output_genre_list:\n",
    "#                 output_genre = output_genre.strip(' ')\n",
    "#     #             print(\"output_genre_created\")\n",
    "#                 if source_genre == output_genre:\n",
    "# #                     print(output_song_index,source_genre,output_genre)\n",
    "# #                     filtered_list.append(output_song_index)\n",
    "#     filtered_lists.append(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_array = np.array([])\n",
    "\n",
    "for row in range(0, 10000):\n",
    "    genre = X.loc[row]['genres_stripped'].split(',')\n",
    "    genre_array = np.append(genre_array, genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = []\n",
    "\n",
    "for row in range(0, 574018):\n",
    "    genre = X.loc[row]['genres_stripped'].split(',')\n",
    "    genre_list.append(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_array = np.array(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_array[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nineteen_tracks = 0 \n",
    "for filtered_list in filtered_lists:\n",
    "    if len(filtered_list) > 19:\n",
    "        nineteen_tracks += 1\n",
    "print(nineteen_tracks / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 = 38%\n",
    " X   = 150%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "150 / 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for index in filtered_list:\n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    display(pd.DataFrame(df.loc[index][0:1]),pd.DataFrame(df.loc[index][1:2]),pd.DataFrame(df.loc[index][17:18]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results1[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1][\"genres_stripped\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = './models/knn_model_v1.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling in the (now) pickled model\n",
    "model_pickle = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model to test on scaled data (not pickled data)\n",
    "pickle_results = model_pickle.kneighbors([data_scaled[1000]])[1]\n",
    "\n",
    "# displaying output\n",
    "pickle_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = './data_scaled.pkl'\n",
    "pickle.dump(data_scaled, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (OLD) Testing both pickles for dataset, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries (even though they are visible above)\n",
    "# to illustrate which packages are needed to create the function below\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "\n",
    "\n",
    "# this function predicts on a song id\n",
    "\n",
    "def predict(id):\n",
    "    #loads in pickled data and model\n",
    "    X = pickle.load(open('./data_scaled.pkl', 'rb'))\n",
    "    loaded_pickle = pickle.load(open('./models/knn_model_v1.pkl', 'rb'))\n",
    "    #calculates results\n",
    "    results = loaded_pickle.kneighbors([X[id]])[1]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {\n",
    "    \"audio_features\": {\n",
    "        \"acousticness\": 0.934,\n",
    "        \"danceability\": 0.186,\n",
    "        \"energy\": 0.107,\n",
    "        \"instrumentalness\": 0,\n",
    "        \"key\": 5,\n",
    "        \"liveness\": 0.297,\n",
    "        \"loudness\": -14.802,\n",
    "        \"mode\": 1,\n",
    "        \"speechiness\": 0.0347,\n",
    "        \"tempo\": 107.095,\n",
    "        \"time_signature\": 4,\n",
    "        \"valence\": 0.149\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame.from_dict(\n",
    "        json_normalize(content['audio_features']),\n",
    "                                orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_scaled = scaler.transform(dataframe)\n",
    "\n",
    "dataframe_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = './models/scaler.pkl'\n",
    "pickle.dump(scaler, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'songid'\n",
    "\n",
    "song_id_array = song_list[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_id_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(song_id_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_id_list = song_id_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(song_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'Flask_API/SOUNDDRIP/data/song_id_array.pkl'\n",
    "pickle.dump(song_id_array, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'song_id_list2.pkl'\n",
    "pickle.dump(song_id_list, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {\n",
    "    \"audio_features\": {\n",
    "        \"acousticness\": 0.934,\n",
    "        \"danceability\": 0.186,\n",
    "        \"energy\": 0.107,\n",
    "        \"instrumentalness\": 0,\n",
    "        \"key\": 5,\n",
    "        \"liveness\": 0.297,\n",
    "        \"loudness\": -14.802,\n",
    "        \"mode\": 1,\n",
    "        \"speechiness\": 0.0347,\n",
    "        \"tempo\": 107.095,\n",
    "        \"time_signature\": 4,\n",
    "        \"valence\": 0.149\n",
    "    }\n",
    "}\n",
    "\n",
    "def predict(content):\n",
    "    print('Loading dataframe...')\n",
    "    dataframe = pd.DataFrame.from_dict(\n",
    "        json_normalize(content['audio_features']),\n",
    "                                orient='columns')\n",
    "    print('Dataframe Object Created')\n",
    "    print('Loading pickled scaler...')\n",
    "    scaler = pickle.load(open('models/scaler.pkl', 'rb'))\n",
    "    print('Pickled scaler loaded')\n",
    "    print('Scaling dataframe object...')\n",
    "    dataframe_scaled = scaler.transform(dataframe)\n",
    "    print('Dataframe scaled')\n",
    "    print('Loading pickled model...')\n",
    "    model = pickle.load(open('./models/knn_model_v1.pkl', 'rb'))\n",
    "    print('Model loaded')\n",
    "    results = model.kneighbors([dataframe_scaled][0])[1]\n",
    "    print('Prediction executed')\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # For-loop for returning 20 songs\n",
    "def all_similarities(data_result):\n",
    "    similar_songs = []\n",
    "    print('song_id_list loading...')\n",
    "    song_id_list = pickle.load(open('Flask_API/SOUNDDRIP/data/song_id_list.pkl', 'rb'))\n",
    "    print('song_id_list loaded')\n",
    "    print('beginning for loop...')\n",
    "    \n",
    "    for song_row in data_result[0][1:]:\n",
    "        song_id = song_id_list[song_row]\n",
    "        similar_songs.append({'similarity': [.99], 'values': song_id})\n",
    "    json_dict = {\"songs\": similar_songs}\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_similarities(predict(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_list = sorted(similarities, key=lambda i: i['similarity'], \n",
    "                                                         reverse=True)[:20]\n",
    "      json_dict = {\"songs\": sorted_list}\n",
    "      #data = json.dumps(json_dict)\n",
    "      return jsonify(json_dict), print('yay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Spotify API Token / Output Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import spotipy.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = 'augt12ocf9csxa4s8kbq9reg8' #your spotify username\n",
    "CLIENT_ID = 'b954b92b9a674e6a9cf7322649da82d1' #set at your developer account\n",
    "CLIENT_SECRET = '920cd41023994b1a99210243ce8967b2' #set at your developer account\n",
    "REDIRECT_URI = 'https://google.com/' #set at your developer account, usually \"http://localhost:8000\"\n",
    "SCOPE = 'user-library-read' # or else\n",
    "# ps. REDIRECT_URI is crucial here. if http://localhost:8000 is not set, or with a single '/' misplaced, it will generate a connection error.\n",
    "\n",
    "# then pass them:\n",
    "\n",
    "token = util.prompt_for_user_token(username = USERNAME, \n",
    "                                   scope = SCOPE, \n",
    "                                   client_id = CLIENT_ID, \n",
    "                                   client_secret = CLIENT_SECRET, \n",
    "                                   redirect_uri = REDIRECT_URI)\n",
    "\n",
    "if token:\n",
    "   sp = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_content = {'token': token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(token_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_content['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(token):\n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "    results = sp.current_user_saved_tracks()\n",
    "    song_id = results['items'][0]['track']['id']\n",
    "    return song_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(song_id):\n",
    "    results_dict = sp.audio_features(song_id)[0]\n",
    "    audio_features = {\"audio_features\":{key: results_dict[key] for key in results_dict.keys() & {'danceability', 'energy',\n",
    "                                                                                                'key', 'loudness', 'mode',\n",
    "                                                                                                'speechiness', 'acousticness',\n",
    "                                                                                                'instrumentalness', 'liveness',\n",
    "                                                                                                'valence', 'tempo', 'time_signature'}}}\n",
    "        \n",
    "    return audio_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " acoustical_features = get_features(get_id(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(content):\n",
    "    similar_songs = []\n",
    "    print('Loading dataframe...')\n",
    "    dataframe = pd.DataFrame.from_dict(\n",
    "        json_normalize(content['audio_features']),\n",
    "                                orient='columns')\n",
    "    print('Dataframe Object Created')\n",
    "    print('Loading pickled scaler...')\n",
    "    scalar = load('scalar2.joblib')\n",
    "    print('Pickled scaler loaded')\n",
    "    print('Scaling dataframe object...')\n",
    "    dataframe_scaled = scalar.transform(dataframe)\n",
    "    print('Dataframe scaled')\n",
    "    print('Loading pickled model...')\n",
    "    model = load('model2.joblib')\n",
    "    print('Model loaded')\n",
    "    results = model.kneighbors([dataframe_scaled][0])[1]\n",
    "    print('Prediction executed')\n",
    "    print('song_id_list loading...')\n",
    "    song_id_list = load('song_id_list2.joblib')\n",
    "    print('song_id_list loaded')\n",
    "    \n",
    "    print('beginning for loop...')\n",
    "    for song_row in results[0][1:]:\n",
    "        song_id = song_id_list[song_row]\n",
    "        similar_songs.append({'similarity': [.99], 'values': song_id})\n",
    "    json_dict = {\"songs\": similar_songs}\n",
    "    return json_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from flask import request\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from flask import jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "\n",
    "predict(acoustical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model, 'model2.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time\n",
    "\n",
    "# pickle_loaded = pickle.load(open('Flask_API/SOUNDDRIP/models/knn_model_v1.pkl', 'rb'))\n",
    "# joblib_loaded = load('model.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(data_scaled, 'data_scaled.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(scaler, 'scalar2.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(song_id_list, 'song_id_list2.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flask_Notebooks",
   "language": "python",
   "name": "flask_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
