{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "# Nearest neighbors will be the v1 model for sound drip\n",
    "# will give logistic regressiona nd \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from flask import request\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from flask import jsonify\n",
    "\n",
    "# textblob will be used to perform sentiment analysis down the road\n",
    "# from textblob import TextBlob\n",
    "\n",
    "# # Data is large and will need to be unzipped\n",
    "# import zipfile\n",
    "\n",
    "# # unzipping file\n",
    "# with zipfile.ZipFile(\"./data_collection/final_data/DF_v1.pkl.zip\",\"r\") as zip_ref:\n",
    "#     zip_ref.extractall(\".\")\n",
    "\n",
    "# # reading in pickled data\n",
    "song_list = pd.read_pickle(\"./DF_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALERT - THIS COULD POTENTIALLY BE USED TO PERFORM SENTIMENT ANALYSIS ON LYRICS DATA IN v2. FOR v1, DISREGARD\n",
    "\n",
    "# # creating polarity and subjectivity lists to be populated\n",
    "\n",
    "# lyrics_polarity = []\n",
    "# lyrics_subjectivity = []\n",
    "\n",
    "# # using a for loop to populate polarity and subjectivity lists\n",
    "# for title in song_list_df[\"lyrics\"]:\n",
    "#     try:\n",
    "#         blob_test = TextBlob = TextBlob(title)\n",
    "#         blob_sentiment = blob_test.sentiment\n",
    "#         # appending results to lists above\n",
    "#         lyrics_polarity.append(blob_sentiment[0])\n",
    "#         lyrics_subjectivity.append(blob_sentiment[1])\n",
    "#     except:\n",
    "#         lyrics_polarity.append(0)\n",
    "#         lyrics_subjectivity.append(0)\n",
    "\n",
    "# # adding polarity and subjectivity to df\n",
    "# song_list['lyrics_polarity'] = lyrics_polarity\n",
    "# song_list['lyrics_subjectivity'] = lyrics_subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning/Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((728156, 16),\n",
       " Index(['acousticness', 'artist', 'danceability', 'duration_ms', 'energy',\n",
       "        'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'songid',\n",
       "        'speechiness', 'tempo', 'time_signature', 'track', 'valence'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_list.shape, song_list.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(728156, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping unnecessary columns\n",
    "X = song_list.drop([\"songid\",\"artist\",\"track\", \"duration_ms\"], axis=1)\n",
    "\n",
    "# checking that they're dropped\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00130522, 0.4884654 , 0.678     , 0.0551    , 0.81818182,\n",
       "       0.0846    , 0.78720453, 1.        , 0.05113636, 0.59980079,\n",
       "       0.8       , 0.87      ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# scaling data\n",
    "data_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# confirming scaling took place\n",
    "data_scaled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is scaled and ready to be fed to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating model class\n",
    "knn = NearestNeighbors(n_neighbors=21,algorithm='kd_tree')\n",
    "\n",
    "# fitting model\n",
    "model = knn.fit(data_scaled)\n",
    "\n",
    "# running model to test output\n",
    "knn_results = knn.kneighbors([data_scaled[1000]])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1000, 647630, 304823, 412399,  48174, 411195, 240739, 537833,\n",
       "         50765, 450355, 151925, 707048, 557285, 508280, 175165, 510531,\n",
       "        652499, 267268, 161932, 587960,  79755]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = './models/knn_model_v1.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling in the (now) pickled model\n",
    "model_pickle = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1000, 647630, 304823, 412399,  48174, 411195, 240739, 537833,\n",
       "         50765, 450355, 151925, 707048, 557285, 508280, 175165, 510531,\n",
       "        652499, 267268, 161932, 587960,  79755]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading model to test on scaled data (not pickled data)\n",
    "pickle_results = model_pickle.kneighbors([data_scaled[1000]])[1]\n",
    "\n",
    "# displaying output\n",
    "pickle_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = './data_scaled.pkl'\n",
    "pickle.dump(data_scaled, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing both pickles for dataset, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries (even though they are visible above)\n",
    "# to illustrate which packages are needed to create the function below\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "\n",
    "\n",
    "# this function predicts on a song id\n",
    "\n",
    "def predict(id):\n",
    "    #loads in pickled data and model\n",
    "    X = pickle.load(open('./data_scaled.pkl', 'rb'))\n",
    "    loaded_pickle = pickle.load(open('./models/knn_model_v1.pkl', 'rb'))\n",
    "    #calculates results\n",
    "    results = loaded_pickle.kneighbors([X[id]])[1]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0, 341644, 462704, 499704, 105639, 347586,  27005, 553442,\n",
       "        594846, 273222, 636137, 218622, 375716,  40341, 510427, 518171,\n",
       "        209537, 168110, 453579, 456931,  89949]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {\n",
    "    \"audio_features\": {\n",
    "        \"acousticness\": 0.934,\n",
    "        \"danceability\": 0.186,\n",
    "        \"energy\": 0.107,\n",
    "        \"instrumentalness\": 0,\n",
    "        \"key\": 5,\n",
    "        \"liveness\": 0.297,\n",
    "        \"loudness\": -14.802,\n",
    "        \"mode\": 1,\n",
    "        \"speechiness\": 0.0347,\n",
    "        \"tempo\": 107.095,\n",
    "        \"time_signature\": 4,\n",
    "        \"valence\": 0.149\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame.from_dict(\n",
    "        json_normalize(content['audio_features']),\n",
    "                                orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-14.802</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>107.095</td>\n",
       "      <td>4</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  energy  instrumentalness  key  liveness  \\\n",
       "0         0.934         0.186   0.107                 0    5     0.297   \n",
       "\n",
       "   loudness  mode  speechiness    tempo  time_signature  valence  \n",
       "0   -14.802     1       0.0347  107.095               4    0.149  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.937751  , 0.18655968, 0.107     , 0.        , 0.45454545,\n",
       "        0.297     , 0.68134949, 1.        , 0.03584711, 0.42840913,\n",
       "        0.8       , 0.149     ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_scaled = scaler.transform(dataframe)\n",
    "\n",
    "dataframe_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = './models/scaler.pkl'\n",
    "pickle.dump(scaler, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'songid'\n",
    "\n",
    "song_id_array = song_list[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         5PS5dpaLogPzYU9hWiWyZb\n",
       "1         41RpZW2lxAdnqDd2nMBzLQ\n",
       "2         2poHURuOfVNbzZdivAwtOH\n",
       "3         1jg9hZnReygpBvV2axGuPy\n",
       "4         3GsS8jzoixpCnp4jDWCEvb\n",
       "                   ...          \n",
       "116091    1xm8J6EFMA6N8JDqH8vzuz\n",
       "116238    4NwmHBjPb9i9N3naLCMVCG\n",
       "116261    5Xo8AsEz0gpW6Rpo2jXvBN\n",
       "116308    4Fnz6vDqufd3ens0Gf9LC5\n",
       "116324    2tolmRzbUfgL5KRplIqHlu\n",
       "Name: songid, Length: 728156, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_id_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-114c8637e68c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_id_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "sys.getsizeof(song_id_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_id_list = song_id_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5825312"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(song_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'Flask_API/SOUNDDRIP/data/song_id_array.pkl'\n",
    "pickle.dump(song_id_array, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'Flask_API/SOUNDDRIP/data/song_id_list.pkl'\n",
    "pickle.dump(song_id_list, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {\n",
    "    \"audio_features\": {\n",
    "        \"acousticness\": 0.934,\n",
    "        \"danceability\": 0.186,\n",
    "        \"energy\": 0.107,\n",
    "        \"instrumentalness\": 0,\n",
    "        \"key\": 5,\n",
    "        \"liveness\": 0.297,\n",
    "        \"loudness\": -14.802,\n",
    "        \"mode\": 1,\n",
    "        \"speechiness\": 0.0347,\n",
    "        \"tempo\": 107.095,\n",
    "        \"time_signature\": 4,\n",
    "        \"valence\": 0.149\n",
    "    }\n",
    "}\n",
    "\n",
    "def predict(content):\n",
    "    print('Loading dataframe...')\n",
    "    dataframe = pd.DataFrame.from_dict(\n",
    "        json_normalize(content['audio_features']),\n",
    "                                orient='columns')\n",
    "    print('Dataframe Object Created')\n",
    "    print('Loading pickled scaler...')\n",
    "    scaler = pickle.load(open('models/scaler.pkl', 'rb'))\n",
    "    print('Pickled scaler loaded')\n",
    "    print('Scaling dataframe object...')\n",
    "    dataframe_scaled = scaler.transform(dataframe)\n",
    "    print('Dataframe scaled')\n",
    "    print('Loading pickled model...')\n",
    "    model = pickle.load(open('./models/knn_model_v1.pkl', 'rb'))\n",
    "    print('Model loaded')\n",
    "    results = model.kneighbors([dataframe_scaled][0])[1]\n",
    "    print('Prediction executed')\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataframe...\n",
      "Dataframe Object Created\n",
      "Loading pickled scaler...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f66d5e90177c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-95fb355ce8eb>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(content)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataframe Object Created'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading pickled scaler...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/scaler.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pickled scaler loaded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scaling dataframe object...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "predict(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # For-loop for returning 20 songs\n",
    "def all_similarities(data_result):\n",
    "    similar_songs = []\n",
    "    print('song_id_list loading...')\n",
    "    song_id_list = pickle.load(open('Flask_API/SOUNDDRIP/data/song_id_list.pkl', 'rb'))\n",
    "    print('song_id_list loaded')\n",
    "    print('beginning for loop...')\n",
    "    \n",
    "    for song_row in data_result[0][1:]:\n",
    "        song_id = song_id_list[song_row]\n",
    "        similar_songs.append({'similarity': [.99], 'values': song_id})\n",
    "    json_dict = {\"songs\": similar_songs}\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataframe...\n",
      "Dataframe Object Created\n",
      "Loading pickled scaler...\n",
      "Pickled scaler loaded\n",
      "Scaling dataframe object...\n",
      "Dataframe scaled\n",
      "Loading pickled model...\n",
      "Model loaded\n",
      "Prediction executed\n",
      "song_id_list loading...\n",
      "song_id_list loaded\n",
      "beginning for loop...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'songs': [{'similarity': [0.99], 'values': '3JeSeOxS09vw7ZaQXyDtkn'},\n",
       "  {'similarity': [0.99], 'values': '0lkEvsJLWu7HjurNUnMYqt'},\n",
       "  {'similarity': [0.99], 'values': '7GrCeh9O4Salm3oEoiDWmf'},\n",
       "  {'similarity': [0.99], 'values': '705JQ49YZOupAYQXrny5Vb'},\n",
       "  {'similarity': [0.99], 'values': '7v6maEWDjrKHQMVFoL8Tq3'},\n",
       "  {'similarity': [0.99], 'values': '6pJeuRa8dj6Hph2r9Unn5H'},\n",
       "  {'similarity': [0.99], 'values': '1XsXX5Q8mCdlDjroYAUs8r'},\n",
       "  {'similarity': [0.99], 'values': '6nl7z8eqCRRNSPJevUg5yJ'},\n",
       "  {'similarity': [0.99], 'values': '4Swt07x4GyojZApyerQ8Ta'},\n",
       "  {'similarity': [0.99], 'values': '68PGQTrsU7NTe6hfcFD3Fh'},\n",
       "  {'similarity': [0.99], 'values': '5jTnsVnWuxdSQnRv124hwL'},\n",
       "  {'similarity': [0.99], 'values': '5YsyWAtEDsStifCxF5d7wJ'},\n",
       "  {'similarity': [0.99], 'values': '4RKMHiQ1sQCJVcPEbqcXR2'},\n",
       "  {'similarity': [0.99], 'values': '7dXTqzYBW6LcuMvfmhKjeS'},\n",
       "  {'similarity': [0.99], 'values': '1pQPfwF8yZejKeu2rZOIwI'},\n",
       "  {'similarity': [0.99], 'values': '2ydHMFR78xJCTaUSgQsY1d'},\n",
       "  {'similarity': [0.99], 'values': '6eUz2WehcJdZamP5qY6Dxh'},\n",
       "  {'similarity': [0.99], 'values': '1JssSjrnWKYEHGNUJ9YgTh'},\n",
       "  {'similarity': [0.99], 'values': '5XmLezxb1jaMurxejpKKYO'},\n",
       "  {'similarity': [0.99], 'values': '3XDBH8yNPbCfuO5xKW1nHI'}]}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarities(predict(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'70jVRf1KHVa4eROjpdmaja'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_list = sorted(similarities, key=lambda i: i['similarity'], \n",
    "                                                         reverse=True)[:20]\n",
    "      json_dict = {\"songs\": sorted_list}\n",
    "      #data = json.dumps(json_dict)\n",
    "      return jsonify(json_dict), print('yay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {\n",
    "    \"audio_features\": {\n",
    "        \"acousticness\": 0.934,\n",
    "        \"danceability\": 0.186,\n",
    "        \"energy\": 0.107,\n",
    "        \"instrumentalness\": 0,\n",
    "        \"key\": 5,\n",
    "        \"liveness\": 0.297,\n",
    "        \"loudness\": -14.802,\n",
    "        \"mode\": 1,\n",
    "        \"speechiness\": 0.0347,\n",
    "        \"tempo\": 107.095,\n",
    "        \"time_signature\": 4,\n",
    "        \"valence\": 0.149\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def predict(content):\n",
    "    similar_songs = []\n",
    "    print('Loading dataframe...')\n",
    "    dataframe = pd.DataFrame.from_dict(\n",
    "        json_normalize(content['audio_features']),\n",
    "                                orient='columns')\n",
    "    print('Dataframe Object Created')\n",
    "    print('Loading pickled scaler...')\n",
    "    scalar = load('scalar2.joblib')\n",
    "    print('Pickled scaler loaded')\n",
    "    print('Scaling dataframe object...')\n",
    "    dataframe_scaled = scalar.transform(dataframe)\n",
    "    print('Dataframe scaled')\n",
    "    print('Loading pickled model...')\n",
    "    model = load('model2.joblib')\n",
    "    print('Model loaded')\n",
    "    results = model.kneighbors([dataframe_scaled][0])[1]\n",
    "    print('Prediction executed')\n",
    "    print('song_id_list loading...')\n",
    "    song_id_list = load('song_id_list2.joblib', 'rb')\n",
    "    print('song_id_list loaded')\n",
    "    \n",
    "    print('beginning for loop...')\n",
    "    for song_row in results[0][1:]:\n",
    "        song_id = song_id_list[song_row]\n",
    "        similar_songs.append({'similarity': [.99], 'values': song_id})\n",
    "    json_dict = {\"songs\": similar_songs}\n",
    "    return json_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.2 µs\n",
      "Loading dataframe...\n",
      "Dataframe Object Created\n",
      "Loading pickled scaler...\n",
      "Pickled scaler loaded\n",
      "Scaling dataframe object...\n",
      "Dataframe scaled\n",
      "Loading pickled model...\n",
      "Model loaded\n",
      "Prediction executed\n",
      "song_id_list loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py:112: UserWarning: mmap_mode \"rb\" is not compatible with compressed file song_id_list2.joblib. \"rb\" flag will be ignored.\n",
      "  return next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_id_list loaded\n",
      "beginning for loop...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'songs': [{'similarity': [0.99], 'values': '3JeSeOxS09vw7ZaQXyDtkn'},\n",
       "  {'similarity': [0.99], 'values': '0lkEvsJLWu7HjurNUnMYqt'},\n",
       "  {'similarity': [0.99], 'values': '7GrCeh9O4Salm3oEoiDWmf'},\n",
       "  {'similarity': [0.99], 'values': '705JQ49YZOupAYQXrny5Vb'},\n",
       "  {'similarity': [0.99], 'values': '7v6maEWDjrKHQMVFoL8Tq3'},\n",
       "  {'similarity': [0.99], 'values': '6pJeuRa8dj6Hph2r9Unn5H'},\n",
       "  {'similarity': [0.99], 'values': '1XsXX5Q8mCdlDjroYAUs8r'},\n",
       "  {'similarity': [0.99], 'values': '6nl7z8eqCRRNSPJevUg5yJ'},\n",
       "  {'similarity': [0.99], 'values': '4Swt07x4GyojZApyerQ8Ta'},\n",
       "  {'similarity': [0.99], 'values': '68PGQTrsU7NTe6hfcFD3Fh'},\n",
       "  {'similarity': [0.99], 'values': '5jTnsVnWuxdSQnRv124hwL'},\n",
       "  {'similarity': [0.99], 'values': '5YsyWAtEDsStifCxF5d7wJ'},\n",
       "  {'similarity': [0.99], 'values': '4RKMHiQ1sQCJVcPEbqcXR2'},\n",
       "  {'similarity': [0.99], 'values': '7dXTqzYBW6LcuMvfmhKjeS'},\n",
       "  {'similarity': [0.99], 'values': '1pQPfwF8yZejKeu2rZOIwI'},\n",
       "  {'similarity': [0.99], 'values': '2ydHMFR78xJCTaUSgQsY1d'},\n",
       "  {'similarity': [0.99], 'values': '6eUz2WehcJdZamP5qY6Dxh'},\n",
       "  {'similarity': [0.99], 'values': '1JssSjrnWKYEHGNUJ9YgTh'},\n",
       "  {'similarity': [0.99], 'values': '5XmLezxb1jaMurxejpKKYO'},\n",
       "  {'similarity': [0.99], 'values': '3XDBH8yNPbCfuO5xKW1nHI'}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "predict(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model2.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, 'model2.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time\n",
    "\n",
    "# pickle_loaded = pickle.load(open('Flask_API/SOUNDDRIP/models/knn_model_v1.pkl', 'rb'))\n",
    "# joblib_loaded = load('model.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(data_scaled, 'data_scaled.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scalar2.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(scaler, 'scalar2.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['song_id_list2.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(song_id_list, 'song_id_list2.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_notebooks",
   "language": "python",
   "name": "model_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
