{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "# Nearest neighbors will be the v1 model for sound drip\n",
    "# will give logistic regressiona nd \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# textblob will be used to perform sentiment analysis down the road\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "# reading in pickled dataset\n",
    "# song_list = pd.read_pickle(\"./data/###.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALERT - THIS COULD POTENTIALLY BE USED TO PERFORM SENTIMENT ANALYSIS ON LYRICS DATA IN v2. FOR v1, DISREGARD\n",
    "\n",
    "# # creating polarity and subjectivity lists to be populated\n",
    "\n",
    "# lyrics_polarity = []\n",
    "# lyrics_subjectivity = []\n",
    "\n",
    "# # using a for loop to populate polarity and subjectivity lists\n",
    "# for title in song_list_df[\"lyrics\"]:\n",
    "#     try:\n",
    "#         blob_test = TextBlob = TextBlob(title)\n",
    "#         blob_sentiment = blob_test.sentiment\n",
    "#         # appending results to lists above\n",
    "#         lyrics_polarity.append(blob_sentiment[0])\n",
    "#         lyrics_subjectivity.append(blob_sentiment[1])\n",
    "#     except:\n",
    "#         lyrics_polarity.append(0)\n",
    "#         lyrics_subjectivity.append(0)\n",
    "\n",
    "# # adding polarity and subjectivity to df\n",
    "# song_list['lyrics_polarity'] = lyrics_polarity\n",
    "# song_list['lyrics_subjectivity'] = lyrics_subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# scaling data\n",
    "data_scalled = scaler.fit_transform(data)\n",
    "\n",
    "# confirming scaling took place\n",
    "data_scaled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is scaled and ready to be fed to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-nearest neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# instantiating model class\n",
    "knn = NearestNeighbors(n_neghbors=10,algorithm='kd_tree')\n",
    "\n",
    "# running model to test output\n",
    "knn_results = nn.kneighbors([data_scaled[1000]])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = './models/knn_model.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pickle = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model to test on scaled data (not pickled data)\n",
    "pickle_results = model_pickle.kneighbors([X_scaled[1000]])[1]\n",
    "\n",
    "# displaying output\n",
    "pickle_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing both pickles for dataset model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries (even though they are visible above)\n",
    "# to illustrate which packages are needed to create the function below\n",
    "\n",
    "import pandas as pd from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "\n",
    "\n",
    "# this function predicts on a song id\n",
    "\n",
    "def predict(id):\n",
    "    #loads in pickled data and model\n",
    "    X = pickle.load(open('./data/X_scaled.pkl', 'rb'))\n",
    "    loaded_pickle = pickle.load(open('./models/knn_model.pkl', 'rb'))\n",
    "    #calculates results\n",
    "    results = loaded_model.kneighbors([X[id]])[1]\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPEnv (Python3)",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
